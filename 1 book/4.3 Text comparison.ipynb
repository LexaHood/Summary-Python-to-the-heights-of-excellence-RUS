{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://itnan.ru/post.php?c=1&p=579868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SHAVE_MARKS\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)  # <1>\n",
    "    shaved = ''.join(c for c in norm_txt\n",
    "                     if not unicodedata.combining(c))  # <2>\n",
    "    return unicodedata.normalize('NFC', shaved)  # <3>\n",
    "# END SHAVE_MARKS\n",
    "\n",
    "# BEGIN SHAVE_MARKS_LATIN\n",
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)  # <1>\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:   # <2>\n",
    "            continue  # ignore diacritic on Latin base char\n",
    "        keepers.append(c)                             # <3>\n",
    "        # if it isn't combining char, it's a new base char\n",
    "        if not unicodedata.combining(c):              # <4>\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)   # <5>\n",
    "    # END SHAVE_MARKS_LATIN\n",
    "\n",
    "# BEGIN ASCIIZE\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\",  # <1>\n",
    "                           \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({  # <2>\n",
    "    '€': '<euro>',\n",
    "    '…': '...',\n",
    "    'Œ': 'OE',\n",
    "    '™': '(TM)',\n",
    "    'œ': 'oe',\n",
    "    '‰': '<per mille>',\n",
    "    '‡': '**',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)  # <3>\n",
    "\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\"\n",
    "    return txt.translate(multi_map)  # <4>\n",
    "\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))     # <5>\n",
    "    no_marks = no_marks.replace('ß', 'ss')          # <6>\n",
    "    return unicodedata.normalize('NFKC', no_marks)  # <7>\n",
    "# END ASCIIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRadical folding and text sanitizing.\\nHandling a string with `cp1252` symbols:\\n    >>> order = \\'“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”\\'\\n    >>> shave_marks(order)\\n    \\'“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\\'\\n    >>> shave_marks_latin(order)\\n    \\'“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\\'\\n    >>> dewinize(order)\\n    \\'\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"\\'\\n    >>> asciize(order)\\n    \\'\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"\\'\\nHandling a string with Greek and Latin accented characters:\\n    >>> greek = \\'Ζέφυρος, Zéfiro\\'\\n    >>> shave_marks(greek)\\n    \\'Ζεφυρος, Zefiro\\'\\n    >>> shave_marks_latin(greek)\\n    \\'Ζέφυρος, Zefiro\\'\\n    >>> dewinize(greek)\\n    \\'Ζέφυρος, Zéfiro\\'\\n    >>> asciize(greek)\\n    \\'Ζέφυρος, Zefiro\\'\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Radical folding and text sanitizing.\n",
    "Handling a string with `cp1252` symbols:\n",
    "    >>> order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "    >>> shave_marks(order)\n",
    "    '“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”'\n",
    "    >>> shave_marks_latin(order)\n",
    "    '“Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”'\n",
    "    >>> dewinize(order)\n",
    "    '\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"'\n",
    "    >>> asciize(order)\n",
    "    '\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"'\n",
    "Handling a string with Greek and Latin accented characters:\n",
    "    >>> greek = 'Ζέφυρος, Zéfiro'\n",
    "    >>> shave_marks(greek)\n",
    "    'Ζεφυρος, Zefiro'\n",
    "    >>> shave_marks_latin(greek)\n",
    "    'Ζέφυρος, Zefiro'\n",
    "    >>> dewinize(greek)\n",
    "    'Ζέφυρος, Zéfiro'\n",
    "    >>> asciize(greek)\n",
    "    'Ζέφυρος, Zefiro'\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bfc6a6397d1d4097ce09be5b592d9ff354b0e54de383685fe25442a1ceea628"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
